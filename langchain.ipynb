{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "## pip install langchain_openai\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinesh\\AppData\\Local\\Temp\\ipykernel_4964\\1308892563.py:2: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm.predict(text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Rainbow Socks Co.\"\n"
     ]
    }
   ],
   "source": [
    "text=\"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinesh\\AppData\\Local\\Temp\\ipykernel_4964\\1977370505.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm(text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Happy Feet Co.\"\n"
     ]
    }
   ],
   "source": [
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Rainbow Footwear Co.\"\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template\n",
    "- Adding a user input to the prompt that we are passing to the large language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for Indian food. Suggest some fancy name\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template='I want to open a restaurant for {cuisine} food. Suggest some fancy name'\n",
    ")\n",
    "\n",
    "p = prompt_template.format(cuisine = \"Indian\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for Indian food. Suggest some fancy name in Mumbai\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['cuisine','location'],\n",
    "    template='I want to open a restaurant for {cuisine} food. Suggest some fancy name in {location}'\n",
    ")\n",
    "\n",
    "p = prompt_template.format(cuisine = \"Indian\", location='Mumbai')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is a good name for a company that makes Soap\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\"what is a good name for a company that makes {product}\")\n",
    "\n",
    "name = prompt_template.format(product='Soap')\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tiny Treasures Co.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate.from_template(\"what is a good name for a company that makes {product} \")\n",
    "prompt.format(product = 'baby products')\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "response = chain.run(\"baby products\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"Nurture & Co.\"\n",
      "2. \"Little Blessings\"\n",
      "3. \"Tiny Tots Co.\"\n",
      "4. \"Babycare Essentials\"\n",
      "5. \"Cherished Little Ones\"\n",
      "6. \"Bundle of Joy Co.\"\n",
      "7. \"Sweet Dreams Baby Co.\"\n",
      "8. \"Lullaby Lane Products\"\n",
      "9. \"Gentle Beginnings Co.\"\n",
      "10. \"Naturally Baby\"\n"
     ]
    }
   ],
   "source": [
    "## we can use it without using prompt.format\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate.from_template(\"what is a good name for a company that makes {product}\")\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "response = chain.run(\"baby products\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### SimpleSequentialChain\n",
    "- Use Case: Suitable for linear, single-input, single-output tasks where each step depends only on the output of the previous  step.\n",
    "- Data Flow: Takes a single input and passes the output of one step as the input to the next step.\n",
    "- Ease of Use: Simpler to set up and use since it doesnâ€™t require handling intermediate variables explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "1. Chicken Tikka Masala\n",
      "2. Lamb Rogan Josh\n",
      "3. Vegetable Biryani\n",
      "4. Tandoori Shrimp\n",
      "5. Palak Paneer (spinach and cheese curry)\n",
      "6. Aloo Gobi (potato and cauliflower curry)\n",
      "7. Dal Makhani (creamy lentil dish)\n",
      "8. Butter Chicken\n",
      "9. Malai Kofta (vegetable and cheese balls in gravy)\n",
      "10. Naan Bread\n",
      "11. Samosas\n",
      "12. Mango Lassi (yogurt drink)\n",
      "13. Chana Masala (spicy chickpea curry)\n",
      "14. Tandoori Chicken\n",
      "15. Gulab Jamun (deep fried milk balls in syrup)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Define LLM\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt1 = PromptTemplate.from_template(\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(\"\"\"Suggest some menu items for {restaurant_name}\"\"\")\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2)\n",
    "\n",
    "simple_chain = SimpleSequentialChain(chains=[chain1,chain2])\n",
    "response = simple_chain.run('indian')\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequentialChain\n",
    "- Use Case: Suitable for more complex workflows where multiple inputs and outputs need to be handled, or when intermediate results are required.\n",
    "- Data Flow: Allows multiple variables to be passed between chains, enabling more flexible interactions.\n",
    "- Flexibility: Provides explicit control over the inputs and outputs at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Indian', 'restaurant_name': '\\n\\n\"The Maharaja\\'s Palace: A Taste of India\"', 'menu_items': '\\n\\nAppetizers:\\n1. Samosas (crispy pastry filled with spiced potatoes and peas)\\n2. Chicken tikka (skewered and grilled chicken in a creamy marinade)\\n3. Papdi chaat (crispy flatbread topped with chickpeas, yogurt, and chutneys)\\n4. Vegetable pakoras (deep-fried fritters made with mixed vegetables)\\n5. Dahi vada (fried lentil balls served in a tangy yogurt sauce)\\n6. Aloo tikki chaat (potato patties topped with chutneys and yogurt)\\n7. Tandoori shrimp (marinated and grilled shrimp)\\n8. Paneer tikka (marinated and grilled cottage cheese)\\n\\nMain Courses:\\n1. Butter chicken (tender chicken cooked in a creamy tomato sauce)\\n2. Palak paneer (cottage cheese cooked in a creamy spinach sauce)\\n3. Lamb biryani (fragrant rice dish with tender lamb pieces)\\n4. Chana masala (spiced chickpeas in a tomato-based curry)\\n5. Chicken tikka masala (grilled chicken cooked in a rich tomato and onion sauce)\\n6. Baingan bharta (smoky mashed eggplant dish with tomatoes and spices'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Define LLM\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt1 = PromptTemplate.from_template(\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\")\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1, output_key = 'restaurant_name')\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(\"\"\"Suggest some menu items for {restaurant_name}\"\"\")\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2, output_key = 'menu_items')\n",
    "\n",
    "simple_chain = SequentialChain(chains=[chain1,chain2],\n",
    "                               input_variables = ['cuisine'],\n",
    "                               output_variables = ['restaurant_name', 'menu_items'])\n",
    "\n",
    "response = simple_chain({'cuisine':\"Indian\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian\n",
      "\n",
      "\n",
      "Appetizers:\n",
      "1. Samosas (crispy pastry filled with spiced potatoes and peas)\n",
      "2. Chicken tikka (skewered and grilled chicken in a creamy marinade)\n",
      "3. Papdi chaat (crispy flatbread topped with chickpeas, yogurt, and chutneys)\n",
      "4. Vegetable pakoras (deep-fried fritters made with mixed vegetables)\n",
      "5. Dahi vada (fried lentil balls served in a tangy yogurt sauce)\n",
      "6. Aloo tikki chaat (potato patties topped with chutneys and yogurt)\n",
      "7. Tandoori shrimp (marinated and grilled shrimp)\n",
      "8. Paneer tikka (marinated and grilled cottage cheese)\n",
      "\n",
      "Main Courses:\n",
      "1. Butter chicken (tender chicken cooked in a creamy tomato sauce)\n",
      "2. Palak paneer (cottage cheese cooked in a creamy spinach sauce)\n",
      "3. Lamb biryani (fragrant rice dish with tender lamb pieces)\n",
      "4. Chana masala (spiced chickpeas in a tomato-based curry)\n",
      "5. Chicken tikka masala (grilled chicken cooked in a rich tomato and onion sauce)\n",
      "6. Baingan bharta (smoky mashed eggplant dish with tomatoes and spices\n",
      "\n",
      "\n",
      "\"The Maharaja's Palace: A Taste of India\"\n"
     ]
    }
   ],
   "source": [
    "print(response['cuisine'])\n",
    "print(response['menu_items'])\n",
    "print(response['restaurant_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
